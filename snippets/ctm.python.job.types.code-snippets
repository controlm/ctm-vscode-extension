{
  "Command Job": {
    "prefix": "jac-Job-Command",
    "body": [
      "job = JobCommand('JobCommandSample',",
      "                 command='mycommand',",
      "                 run_as='user',",
      "                 host='myhost.com',",
      "                 pre_command='echo Precommand',",
      "                 post_command='echo Finished')"
    ],
    "description": "The following example shows how to use the Job:Command to run operating system commands."
  },
  "Script Job": {
    "prefix": "jac-Job-Script",
    "body": [
      "job = JobScript('JobScriptSame',",
      "                file_name='task.sh',",
      "                file_path='%%path',",
      "                run_as='user',",
      "                arguments=['arg1', 'arg2'],",
      "                variables=[{'path': '/home/scripts'}])"
    ],
    "description": "The following example shows how to use Job:Script to run a script from a specified script file."
  },
  "Embedded Script Job": {
    "prefix": "jac-Job-Script-Embedded",
    "body": [
      "job = JobEmbeddedScript('JobEmbeddedScriptSample',",
      "                        file_name='filename.sh',",
      "                        script=r'#!/bin/bash\\necho \"Hello\"\\necho \"Bye\"'),"
    ],
    "description": "Inserts an Embedded Script job"
  },
  "File Transfer Job Local": {
    "prefix": "jac-Job-FileTransferLocal",
    "body": [
      "job = JobFileTransfer('JobFileTransferSample',",
      "                      connection_profile_src='CP1', connection_profile_dest='CP2',",
      "                      number_of_retries='7',",
      "                      file_transfers=[",
      "                          FileTransfer(src='/home/ctm/file1', dest='/home/cmt/file2',",
      "                                       transfer_type=FileTransfer.TransferType.Binary,",
      "                                       transfer_option=FileTransfer.TransferOption.SrcToDest),",
      "",
      "                          FileTransfer(src='/home/ctm/file1', dest='/home/cmt/file2',",
      "                                       transfer_type=FileTransfer.TransferType.Binary,",
      "                                       transfer_option=FileTransfer.TransferOption.SrcToDest),",
      "                      ])"
    ],
    "description": "The following example shows a Job:FileTransfer for a file transfer from a local filesystem to an SFTP server"
  },
  "File Transfer Job S3 to Local": {
    "prefix": "jac-Job-File-Transfer-S3-Local",
    "body": [
      "job = JobFileTransfer('TransferS3ToLocal',",
      "                      connection_profile_src='amazonCP', connection_profile_dest='localcp',",
      "                      s3_bucket_name='bucket')"
    ],
    "description": "The following example shows a Job:FileTransfer for a file transfer from a S3 filesystem to local folder"
  },
  "File Watcher Create Job": {
    "prefix": "jac-Job-File-Watcher-Create",
    "body": [
      "job = JobFileWatcherCreate('JobFileWatcherCreateSample',",
      "                           path='C:\\\\path*.txt',",
      "                           search_interval='45',",
      "                           time_limit='22',",
      "                           start_time='201705041535',",
      "                           stop_time='201805041535',",
      "                           minimum_size='10B',",
      "                           wildcard=False,",
      "                           minimal_age='1Y',",
      "                           maximal_age='1D2H4MIN'",
      "                           )",
      ""
    ],
    "description": "A File Watcher job enables you to detect the successful completion of a file transfer activity that creates or deletes a file."
  },
  "File Watcher Delte Job": {
    "prefix": "jac-Job-File-Watcher-Delete",
    "body": [
      "job = JobFileWatcherDelete('JobFileWatcherDeleteSample',",
      "                           path='C:\\\\path*.txt',",
      "                           search_interval='45',",
      "                           time_limit='22',",
      "                           start_time='201705041535',",
      "                           stop_time='201805041535',",
      "                           )"
    ],
    "description": "A File Watcher job enables you to detect the successful completion of a file transfer activity that creates or deletes a file."
  },
  "Database Embedded Query": {
    "prefix": "jac-Job-Database-Embedded-Query",
    "body": [
      "job = JobDatabaseEmbeddedQuery(",
      "    'JobEmbeddedQuerySample',",
      "    query='SELECT %%firstParamName AS VAR1 \\\\n FROM DUMMY \\\\n ORDER BY \\\\t VAR1 DESC',",
      "    connection_profile='CPDB',",
      "    variables=[{'firstParamName': 'value'}],",
      "    autocommit='N',",
      "    output_execution_log='y',",
      "    output_sql_output='y',",
      "    sql_output_format='XML'",
      ")",
      ""
    ],
    "description": "The following example shows how to create a database job that runs an embedded query."
  },
  "Database SQL Script Basic": {
    "prefix": "jac-Job-Database-SQL-Script-Basic",
    "body": [
      "job = JobDatabaseSQLScript('JobDatabaseSQLScriptSample',",
      "                           connection_profile='CPDB',",
      "                           sql_script='/home/script.sql',",
      "                           parameters=[{'param1': 'val1'}, {'param2': 'val2'}])",
      ""
    ],
    "description": "The following example shows how to create a database job that runs a SQL script from a file system."
  },
  "Database Stored Procedure": {
    "prefix": "jac-Job-Database-Stored-Procedure",
    "body": [
      "job = JobDatabaseStoredProcedure('JobDatabaseStoredProcedureSample',",
      "                                 connection_profile='CPDB',",
      "                                 stored_procedure='procedure',",
      "                                 schema='public',",
      "                                 return_value='RV')"
    ],
    "description": "The following example shows how to create a database job that runs a program that is stored on the database."
  },
  "Database MSSQL Agent Job": {
    "prefix": "jac-Job-Database-MSSQL-Agent-Job",
    "body": [
      "job = JobDatabaseMSSQLAgentJob('JobDatabaseMSSQLAgentJobSample',",
      "                               job_name='get_version',",
      "                               connection_profile='CPDB',",
      "                               category='Data Collector')",
      ""
    ],
    "description": "The following example shows how to create an MSSQL Agent job, for management of a job defined in the SQL server."
  },
  "Database MSSQL SSIS": {
    "prefix": "jac-Job-Database-MSSQL-SSIS",
    "body": [
      "job = JobDatabaseMSSQL_SSIS('JobDatabaseMSSQL_SSISSample',",
      "                           connection_profile='CPDB',",
      "                           package_source=JobDatabaseMSSQL_SSIS.PackageSource.SSIS_Catalog,",
      "                           package_name='\\\\Data Collector\\\\SqlTraceCollect',",
      "                           catalog_env='ENV_NAME',",
      "                           config_files=[",
      "                               'C:\\\\Users\\\\dbauser\\\\Desktop\\\\test.dtsConfig',",
      "                               'C:\\\\Users\\\\dbauser\\\\Desktop\\\\test2.dtsConfig'",
      "                           ],",
      "                           properties=[{",
      "                               'PropertyName': 'PropertyValue'",
      "                           },",
      "                               {",
      "                               'PropertyName2': 'PropertyValue2'",
      "                           }]",
      "                           )",
      ""
    ],
    "description": "The following example shows how to create SSIS Package jobs for execution of SQL Server Integration Services (SSIS) packages"
  },
  "Hadoop Spark Python Basic": {
    "prefix": "jac-Job-Hadoop-Spark-Python-Basic",
    "body": [
      "job = JobHadoopSparkPython('JobHadoopSparkPythonSample',",
      "                           connection_profile='CP',",
      "                           spark_script='/home/process.py')",
      ""
    ],
    "description": "The following example shows how to use Job:Hadoop:Spark:Python to run a Spark Python program."
  },
  "Hadoop Spark Python Advanced": {
    "prefix": "jac-Job-Hadoop-Spark-Python-Advanced",
    "body": [
      "job = JobHadoopSparkPython('JobHadoopSparkPythonSample',",
      "                           connection_profile='CP',",
      "                           spark_script='/home/process.py',",
      "                           arguments=[",
      "                               '1000',",
      "                               '120'",
      "                           ],",
      "                           spark_options=[{'--master': 'yarn'},",
      "                                          {'--num': '-executors 50'}]",
      "                           )",
      ""
    ],
    "description": "The following example shows how to use Job:Hadoop:Spark:Python to run a Spark Python program."
  },
  "Hadoop Spark Scala Java Basic": {
    "prefix": "jac-Job-Hadoop-Spark-Scala-Java-Basic",
    "body": [
      "job = JobHadoopSparkScalaJava('JobHadoopSparkScalaJavaSample',",
      "                              connection_profile='CP',",
      "                              program_jar='/home/user/ScalaProgram.jar',",
      "                              main_class='com.mycomp.sparkScalaProgramName.mainClassName'",
      "                              )"
    ],
    "description": "The following example shows how to use Job:Hadoop:Spark:ScalaJava to run a Spark Java or Scala program."
  },
  "Hadoop Pig Basic": {
    "prefix": "jac-Job-Hadoop-Pig-Basic",
    "body": [
      "job = JobHadoopPig('JobHadoopPigSample',",
      "                   connection_profile='CP',",
      "                   pig_script='/home/user/script.pg'",
      "                   )"
    ],
    "description": "The following example shows how to use Job:Hadoop:Pig to run a Pig script."
  },
  "Hadoop Sqoop Basic": {
    "prefix": "jac-Job-Hadoop-Sqoop-Basic",
    "body": [
      "job = JobHadoopSqoop('JobHadoopSqoopSample',",
      "                     connection_profile='CP',",
      "                     sqoop_command='import --table foo --target-dir /dest_dir',",
      "                     sqoop_options=[",
      "                         {\"--warehouse-dir\": \"/shared\"},",
      "                         {\"--default-character-set\": \"latin1\"}",
      "                     ]",
      "                     )"
    ],
    "description": "The following example shows how to use Job:Hadoop:Sqoop to run a Sqoop job."
  },
  "Hadoop Hive Basic": {
    "prefix": "jac-Job-Hadoop-Hive-Basic",
    "body": [
      "job = JobHadoopHive('JobHadoopHiveSample',",
      "                    connection_profile='CP',",
      "                    hive_script='/home/user1/hive.script',",
      "                    parameters=[{'amount': '1000'}, {'topic': 'food'}],",
      "                    hive_options={'hive.root.logger': 'INFO, console'})",
      ""
    ],
    "description": "The following example shows how to use Job:Hadoop:Hive to run a Hive beeline job."
  },
  "Hadoop Distributed Copy Basic": {
    "prefix": "jac-Job-Hadoop-Dist-Cp-Basic",
    "body": [
      "job = JobHadoopDistCp('JobHadoopDistCpSample',",
      "                      connection_profile='CP',",
      "                      target_path='hdfs://nns2:8020/foo/bar',",
      "                      source_paths=['hdfs://nns1:8020/foo/a'],",
      "                      distcp_options=[{'-m': '3'}, {'-filelimit': '100'}]",
      "                      )"
    ],
    "description": "The following example shows how to use Job:Hadoop:DistCp to run a DistCp job.  DistCp (distributed copy) is a tool used for large inter/intra-cluster copying."
  },
  "Hadoop HDFS Commands": {
    "prefix": "jac-Job-Hadoop-HDFS-Commands",
    "body": [
      "job = JobHadoopHDFSCommands('JobHadoopHDFSCommandsSample',",
      "                            connection_profile='CP',",
      "                            commands=[{\"get\": \"hdfs://nn.example.com/user/hadoop/file localfile\"},",
      "                                      {\"rm\": \"hdfs://nn.example.com/file /user/hadoop/emptydir\"}]",
      "                            )"
    ],
    "description": "The following example shows how to use Job:Hadoop:HDFSCommands to run a job that executes one or more HDFS commands."
  },
  "Hadoop HDFS File Watcher": {
    "prefix": "jac-Job-Hadoop-HDFS-File-Watcher",
    "body": [
      "job = JobHadoopHDFSFileWatcher('JobHadoopHDFSFileWatcherSample',",
      "                               connection_profile='CP',",
      "                               hdfs_file_path='/input/filename',",
      "                               min_detected_size='1',",
      "                               max_wait_time='2'",
      "                               )"
    ],
    "description": "The following example shows how to use Job:Hadoop:HDFSFileWatcher to run a job that waits for HDFS file arrival."
  },
  "Hadoop Oozie": {
    "prefix": "jac-Job-Hadoop-Oozie",
    "body": [
      "job = JobHadoopOozie('JobHadoopOozieSample',",
      "                     connection_profile='CP',",
      "                     job_properties_file='/home/user/job.properties',",
      "                     oozie_options=[{\"inputDir\": \"/usr/tucu/inputdir\"},",
      "                                    {\"outputDir\": \"/usr/tucu/outputdir\"}]",
      "                     )",
      ""
    ],
    "description": "The following example shows how to use Job:Hadoop:Oozie to run a job that submits an Oozie workflow."
  },
  "Hadoop MapReduce Basic": {
    "prefix": "jac-Job-Hadoop-Map-Reduce-Basic",
    "body": [
      "job = JobHadoopMapReduce('JobHadoopMapReduceSample',",
      "                         connection_profile='CP',",
      "                         program_jar='/home/user1/hadoop-jobs/hadoop-mapreduce-examples.jar',",
      "                         main_class='com.mycomp.mainClassName',",
      "                         arguments=[",
      "                             'arg1',",
      "                             'arg2'",
      "                         ])"
    ],
    "description": "The following example shows how to use Job:Hadoop:MapReduce to execute a Hadoop MapReduce job."
  },
  "Hadoop MapReduce Streaming": {
    "prefix": "jac-Job-Hadoop-Map-Reduce-Streaming",
    "body": [
      "job = JobHadoopMapredStreaming('JobHadoopMapredStreamingSample',",
      "                               connection_profile='CP',",
      "                               input_path='/user/input/',",
      "                               output_path='/tmp/output',",
      "                               mapper_command='mapper.py',",
      "                               reducer_command='reducer.py',",
      "                               general_options=[",
      "                                   {\"-D\": \"fs.permissions.umask-mode=000\"},",
      "                                   {\"-files\": \"/home/user/hadoop-streaming/mapper.py,/home/user/hadoop-streaming/reducer.py\"}",
      "                               ]",
      "                               )"
    ],
    "description": "The following example shows how to use Job:Hadoop:MapredStreaming to execute a Hadoop MapReduce Streaming job."
  },
  "Hadoop Tajo InputFile": {
    "prefix": "jac-Job-Hadoop-Tajo-Input-File",
    "body": [
      "job = JobHadoopTajoInputFile('JobHadoopTajoInputFileSample',",
      "                             connection_profile='CP',",
      "                             full_file_path='/home/user/tajo_command.sh',",
      "                             tajo_options=[",
      "                                 {\"amount\": \"1000\"},",
      "                                 {\"volume\": \"120\"}",
      "                             ]",
      "                             )"
    ],
    "description": "The following example shows how to execute a Hadoop Tajo job based on an input file."
  },
  "Hadoop Tajo Query": {
    "prefix": "jac-Job-Hadoop-Tajo-Query",
    "body": [
      "job = JobHadoopTajoQuery('JobHadoopTajoQuerySample',",
      "                         connection_profile='CP',",
      "                         open_query='SELECT %%firstParamName AS VAR1 \\\\n FROM DUMMY \\\\n ORDER BY \\\\t VAR1 DESC')",
      ""
    ],
    "description": "The following example shows how to execute a Hadoop Tajo job based on a query."
  },
  "PeopleSoft": {
    "prefix": "jac-Job-PeopleSoft",
    "body": [
      "job = JobPeopleSoft('JobPeopleSoftSample',",
      "                    connection_profile='CP_PS',",
      "                    user='PS_User',",
      "                    control_id='controlid',",
      "                    server_name='server',",
      "                    process_type='ptype',",
      "                    process_name='pname',",
      "                    append_to_output=False,",
      "                    bind_variables=['val1', 'val2'])",
      ""
    ],
    "description": "The following example shows the JSON code used to define a PeopleSoft job."
  },
  "Informatica": {
    "prefix": "jac-Job-Informatica",
    "body": [
      "job = JobInformatica('JobInformaticaSample',",
      "               connection_profile='CP_INF',",
      "               repository_folder='POC',",
      "               workflow='WF_TEST',",
      "               instance_name='MyInstance',",
      "               os_profile='OSPROFILE',",
      "               workflow_execution_mode=JobInformatica.WorkflowExecutionMode.RunSingleTask,",
      "               workflow_restart_mode=JobInformatica.WorkflowRestartMode.ForceRestartFromSpecificTask,",
      "               restart_from_task='s_MapTest_Success',",
      "               workflow_parameters_file='/opt/wf1.prop')"
    ],
    "description": "The following example shows the JSON code used to define an Informatica job."
  },
  "AWS Lambda": {
    "prefix": "jac-Job-AWS-Lambda",
    "body": [
      "job = JobAWSLambda('JobAWSLambdaSample',",
      "                   connection_profile='CPAWS',",
      "                   function_name='fname',",
      "                   version='1',",
      "                   payload='{\"myVar\":\"value1\", \"othervar\":\"value2\"}',",
      "                   append_log=True",
      "                   )",
      ""
    ],
    "description": "The following example shows how to define a job that executes an AWS Lambda service on an AWS server."
  },
  "AWS Step Function": {
    "prefix": "jac-Job-AWS-Step-Function",
    "body": [
      "job = JobAWSStepFunction('JobAWSStepFunctionSample',",
      "                         connection_profile='CPAWS',",
      "                         state_machine='smach1',",
      "                         execution_name='exec1',",
      "                         input='{\"var\":\"value\", \"othervar\":\"val2\"}',",
      "                         append_log=False)",
      ""
    ],
    "description": "The following example shows how to define a job that executes an AWS Step Function service on an AWS server."
  },
  "AWS Batch": {
    "prefix": "jac-Job-AWS-Batch",
    "body": [
      "job = JobAWSBatch('JobAWSBatchSample',",
      "                  connection_profile='CPAWS',",
      "                  job_name='batchjob',",
      "                  job_definition='jobdef',",
      "                  job_definition_revision='3',",
      "                  job_queue='queue1',",
      "                  aws_job_type=JobAWSBatch.AwsJobType.Array,",
      "                  array_size='100',",
      "                  depends_on=JobAWSBatch.DependsOn(",
      "                      dependency_type=JobAWSBatch.DependsOn.DependencyType.Standard,",
      "                      job_depends_on='job5'),",
      "                  command='ls',",
      "                  memory='10',",
      "                  v_cpus='2',",
      "                  job_attempts='5',",
      "                  execution_timeout='60',",
      "                  append_log=False)",
      ""
    ],
    "description": "The following example shows how to define a job that executes an AWS Batch service on an AWS server."
  },
  "Azure Function": {
    "prefix": "jac-Job-Azure-Function",
    "body": [
      "job = JobAzureFunction('JobAzureFunctionSample',",
      "                       connection_profile='CPAZURE',",
      "                       function='AzureFunction',",
      "                       function_app='funcapp',",
      "                       append_log=False,",
      "                       parameters=[",
      "                           {\"firstParamName\": \"firstParamValue\"},",
      "                           {\"secondParamName\": \"secondParamValue\"}",
      "                       ])"
    ],
    "description": "The following example shows how to define a job that executes an Azure function service."
  },
  "Azure Logic Apps": {
    "prefix": "jac-Job-Azure-Logic-Apps",
    "body": [
      "job = JobAzureLogicApps('JobAzureLogicAppsSample',",
      "                        connection_profile='CPAZURE',",
      "                        logic_app_name='logic_app',",
      "                        request_body='{\"name\":\"value\"}',",
      "                        append_log=True)"
    ],
    "description": "The following example shows how to define a job that executes an Azure logic App service."
  },
  "Azure Batch Account": {
    "prefix": "jac-Job-Azure-Batch-Account",
    "body": [
      "job = JobAzureBatchAccount('JobAzureBatchAccountSample',",
      "                           connection_profile='CPAZURE',",
      "                           job_id='azurejob',",
      "                           command_line='echo \"Hello\"',",
      "                           append_log=True,",
      "                           wallclock=JobAzureBatchAccount.Wallclock(",
      "                               time='70', unit=JobAzureBatchAccount.Wallclock.Unit.Minutes),",
      "                           max_tries=JobAzureBatchAccount.MaxTries(",
      "                               count='6', option=JobAzureBatchAccount.MaxTries.Option.Custom),",
      "                           retention=JobAzureBatchAccount.Retention(",
      "                               time='1', unit=JobAzureBatchAccount.Retention.Unit.Hours)",
      "                           )",
      ""
    ],
    "description": "The following example shows how to define a job that executes an Azure Batch Account service."
  },
  "WebServices": {
    "prefix": "jac-Job-WebServices",
    "body": [
      "job = JobWebServices('JobWebServicesSample',",
      "                     connection_profile='CP_WS',",
      "                     location='http://www.dneonline.com/calculator.asmx?WSDL',",
      "                     soap_header_file='c:\\\\myheader.txt',",
      "                     service='Calculator(Port:CalculatorSoap)',",
      "                     operation='Add',",
      "                     request_type=JobWebServices.RequestType.Parameter,",
      "                     override_url_endpoint='http://myoverridehost.com',",
      "                     override_content_type='*/*',",
      "                     http_connection_timeout='2345',",
      "                     preemptive_http_authentication='abc@bmc.com',",
      "                     include_title_in_output=True,",
      "                     exclude_job_output=False,",
      "                     output_parameters=[{",
      "                         \"Element\": \"AddResponse.AddResult\",",
      "                         \"HttpCode\": \"*\",",
      "                         \"Destination\": \"testResultAdd\",",
      "                         \"Type\": \"string\"",
      "                     }],",
      "                     input_parameters=[",
      "                         {",
      "                             \"Name\": \"intA\",",
      "                             \"Value\": \"97\",",
      "                             \"Type\": \"string\"",
      "                         },",
      "                         {",
      "                             \"Name\": \"intB\",",
      "                             \"Value\": \"345\",",
      "                             \"Type\": \"string\"",
      "                         },",
      "                         {",
      "                             \"Name\": \"accept-encoding\",",
      "                             \"Value\": \"*/*\",",
      "                             \"Type\": \"header\"",
      "                         }",
      "                     ],",
      "                     soap_request=[",
      "                         '''<soapenv:Envelope xmlns:soapenv=http://schemas.xmlsoap.org/soap/envelope/ xmlns:tem=http://tempuri.org/>",
      "                                <soapenv:Header/>",
      "                                <soapenv:Body>",
      "                                    <tem:Add>",
      "                                        <tem:intA>98978</tem:intA>",
      "                                        <tem:intB>75675</tem:intB>",
      "                                    </tem:Add>",
      "                                </soapenv:Body>",
      "                            </soapenv:Envelope>'''",
      "                     ],",
      "                     input_file='/home/usr/soap.xml')",
      ""
    ],
    "description": "The following example presents a Web Services job that receives input for a calculator service and outputs the result of a simple calculation"
  },
  "SLA Management": {
    "prefix": "jac-Job-SLA-Management",
    "body": [
      "job = JobSLAManagement('JobSLAManagementSample',",
      "                       service_name='SLA-service',",
      "                       service_priority='1',",
      "                       job_runs_deviations_tolerance='1',",
      "                       complete_in=JobSLAManagement.CompleteIn(time='00:01'),",
      "                       complete_by=JobSLAManagement.CompleteBy(",
      "                           time='21:40', days='3'),",
      "                       average_run_time_tolerance=JobSLAManagement.AverageRunTimeTolerance(",
      "                           average_run_time='10',",
      "                           units=JobSLAManagement.AverageRunTimeTolerance.Units.Minutes",
      "                       ))"
    ],
    "description": "SLA Management jobs enable you to identify a chain of jobs that comprise a critical service and must complete by a certain time."
  }
}