{
    "Command Job": {
        "prefix": "jac.job.Command",
        "body": "\"MyCommandJob\": {\"Type\" : \"Job:Command\",\"Command\" : \"echo hello\",\"PreCommand\": \"echo before running main command\",\"PostCommand\": \"echo after running main command\",\"Host\" : \"myhost.mycomp.com\",\"RunAs\" : \"user1\"",
        "description": "The following example shows how to use the Job:Command to run operating system commands."
    },
    "Script Job": {
        "prefix": "jac.job.Script",
        "body": "\"MyJobWithPreAndPost\": {\"Type\" : \"Job:Script\",\"FileName\" : \"task1123.sh\",\"FilePath\" : \"/home/user1/scripts\",\"PreCommand\": \"echo before running script\",\"PostCommand\": \"echo after running script\",\"Host\" : \"myhost.mycomp.com\",\"RunAs\" : \"user1\",\"Arguments\":[\"arg1\",\"arg2\"]",
        "description": "The following example shows how to use Job:Script to run a script from a specified script file."
    },
    "Embedded Script Job": {
        "prefix": "jac.job.Script.Embedded",
        "body": "\"MyEmbeddedScriptJob\":{\"Type\":\"Job:EmbeddedScript\", \"Script\":\"#!/bin/bash\\necho \\\"Hello world\\\"\",\"Host\":\"myhost.mycomp.com\",\"RunAs\":\"user1\",\"FileName\":\"myscript.sh\",\"PreCommand\": \"echo before running script\",\"PostCommand\": \"echo after running script\",\"Arguments\":[ \"arg1\",\"arg2\" ]",
        "description": "Inserts an Embedded Script job"
    },
    "Script Job with Pre & Post Command": {
        "prefix": "jac.job.Script.Pre.Post",
        "body": "\"MyJobWithPreAndPost\": {\"Type\" : \"Job:Script\", \"FileName\" : \"task1123.sh\",\"FilePath\" : \"/home/user1/scripts\",\"PreCommand\": \"echo before running script\",\"PostCommand\": \"echo after running script\",\"Host\" : \"myhost.mycomp.com\",\"RunAs\" : \"user1\"\"Arguments\":[\"arg1\",\"arg2\"]",
        "description": "Inserts an Embedded Script job"
    },
    "File Transfer Job Local to SFTP": {
        "prefix": "jac.job.File.Transfer.Local.SFTP",
        "body": "\"MyFileTransferFolder\":{\"Type\":\"Folder\",\"Application\":\"aft\",\"TransferFromLocalToSFTP\":{\"Type\":\"Job:FileTransfer\",\"ConnectionProfileSrc\":\"LocalConn\",\"ConnectionProfileDest\":\"SftpConn\",\"NumberOfRetries\":\"3\",\"Host\":\"AgentHost\",\"FileTransfers\":[{\"Src\":\"/home/controlm/file1\",\"Dest\":\"/home/controlm/file2\",\"TransferType\":\"Binary\",\"TransferOption\":\"SrcToDest\"},{\"Src\":\"/home/controlm/otherFile1\",\"Dest\":\"/home/controlm/otherFile2\",\"TransferOption\":\"DestToSrc\"}]}}",
        "description": "The following example shows a Job:FileTransfer for a file transfer from a local filesystem to an SFTP server"
    },
    "File Transfer Job S3 to Local": {
        "prefix": "jac.job.File.Transfer.S3.Local",
        "body": "\"MyS3AftFolder\":{\"Type\":\"Folder\",\"Application\":\"aft\",\"TransferFromS3toLocal\":{\"Type\":\"Job:FileTransfer\",\"ConnectionProfileSrc\":\"amazonConn\",\"ConnectionProfileDest\":\"LocalConn\",\"NumberOfRetries\":\"4\",\"S3BucketName\":\"bucket1\",\"Host\":\"agentHost\",\"FileTransfers\":[{\"Src\":\"folder/sub_folder/file1\",\"Dest\":\"folder/sub_folder/file2\"}]}}",
        "description": "The following example shows a Job:FileTransfer for a file transfer from a S3 filesystem to local folder"
    },
    "File Transfer Job S3 to S3": {
        "prefix": "jac.job.File.Transfer.S3.S3",
        "body": "\"MyS3AftFolder\":{\"Type\":\"Folder\",\"Application\":\"aft\",\"TransferFromS3toS3\":{\"Type\":\"Job:FileTransfer\",\"ConnectionProfileSrc\":\"amazonConn\",\"ConnectionProfileDest\":\"amazon2Conn\",\"NumberOfRetries\":\"6\",\"S3BucketNameSrc\":\"bucket1\",\"S3BucketNameDest\":\"bucket2\",\"Host\":\"agentHost\",\"FileTransfers\":[{\"Src\":\"folder/sub_folder/file1\",\"Dest\":\"folder/sub_folder/file2\"}]}}",
        "description": "The following example shows a Job:FileTransfer for a file transfer from a S3 to S3 filesystem"
    },
    "File Transfer Job Local to AS2": {
        "prefix": "jac.job.File.Transfer.Local.AS2",
        "body": "\"MyAs2AftFolder\":{\"Type\":\"Folder\",\"Application\":\"AFT\",\"MyAftJob_AS2\":{\"Type\":\"Job:FileTransfer\",\"ConnectionProfileSrc\":\"localAConn\",\"ConnectionProfileDest\":\"as2Conn\",\"NumberOfRetries\":\"Default\",\"Host\":\"agentHost\",\"FileTransfers\":[{\"Src\":\"/dev\",\"Dest\":\"/home/controlm/\",\"As2Subject\":\"Override subject\",\"As2Message\":\"Override conntent type\"}]}}",
        "description": "The following example shows a Job:FileTransfer for a file transfer from local filesystem to AS2"
    },
    "File Watcher Transfer Job based on Event": {
        "prefix": "jac.job.File.Transfer.Event.Based",
        "body": "{\"MyFileTransferFolder\":{\"Type\":\"Folder\",\"Application\":\"aft\",\"TransferFromLocalToSFTPBasedOnEvent\":{\"Type\":\"Job:FileTransfer\",\"Host\":\"AgentHost\",\"ConnectionProfileSrc\":\"LocalConn\",\"ConnectionProfileDest\":\"SftpConn\",\"NumberOfRetries\":\"3\",\"FileTransfers\":[{\"Src\":\"/home/sftp/file1\",\"Dest\":\"/home/sftp/file2\",\"TransferType\":\"Binary\",\"TransferOption\":\"SrcToDestFileWatcher\",\"PreCommandDest\":{\"action\":\"rm\",\"arg1\":\"/home/sftp/file2\"},\"PostCommandDest\":{\"action\":\"chmod\",\"arg1\":\"700\",\"arg2\":\"/home/sftp/file2\"},\"FileWatcherOptions\":{\"MinDetectedSizeInBytes\":\"200\",\"TimeLimitPolicy\":\"WaitUntil\",\"TimeLimitValue\":\"2000\",\"MinFileAge\":\"3Min\",\"MaxFileAge\":\"10Min\",\"AssignFileNameToVariable\":\"FileNameEvent\",\"TransferAllMatchingFiles\":true}}]}}}",
        "description": "The following example presents a File Transfer job in which the transferred file is watched using the File Watcher utility"
    },
    "File Watcher Create Job": {
        "prefix": "jac.job.File.Watcher.Create",
        "body": "\"MyFWJobCreate\":{\"Type\":\"Job:FileWatcher:Create\",\"RunAs\":\"controlm\",\"Path\":\"C:/path*.txt\",\"SearchInterval\":\"45\",\"TimeLimit\":\"22\",\"StartTime\":\"201705041535\",\"StopTime\":\"201805041535\",\"MinimumSize\":\"10B\",\"WildCard\":true,\"MinimalAge\":\"1Y\",\"MaximalAge\":\"1D2H4MIN\"}",
        "description": "A File Watcher job enables you to detect the successful completion of a file transfer activity that creates or deletes a file."
    },
    "File Watcher Delte Job": {
        "prefix": "jac.job.File.Watcher.Delete",
        "body": "\"MyFWJobDelete\":{\"Type\":\"Job:FileWatcher:Delete\",\"RunAs\":\"controlm\",\"Path\":\"C:/path.txt\",\"SearchInterval\":\"45\",\"TimeLimit\":\"22\",\"StartTime\":\"201805041535\",\"StopTime\":\"201905041535\"}",
        "description": "A File Watcher job enables you to detect the successful completion of a file transfer activity that creates or deletes a file."
    },
    "Database Embedded Query": {
        "prefix": "jac.job.Database.Embedded.Query",
        "body": "{\"MyPostgresDBFolder\":{\"Type\":\"Folder\",\"EmbeddedQueryJobName\":{\"Type\":\"Job:Database:EmbeddedQuery\",\"ConnectionProfile\":\"POSTGRESQL_CONNECTION_PROFILE\",\"Query\":\"SELECT %%firstParamName AS VAR1 \\n FROM DUMMY \\n ORDER BY \\t VAR1 DESC\",\"Host\":\"${agentName}\",\"RunAs\":\"PostgressCP\",\"Variables\":[{\"firstParamName\":\"firstParamValue\"}],\"Autocommit\":\"N\",\"OutputExecutionlog\":\"Y\",\"OutputSQLOutput\":\"Y\",\"SQLOutputFormat\":\"XML\"}}}",
        "description": "The following example shows how to create a database job that runs an embedded query."
    },
    "Database SQL Script with Parameters": {
        "prefix": "jac.job.Database.SQL.Script.Parameters",
        "body": "{\"MyOracleDBFolder\":{\"Type\":\"Folder\",\"testOracle\":{\"Type\":\"Job:Database:SQLScript\",\"Host\":\"AgentHost\",\"SQLScript\":\"/home/controlm/sqlscripts/selectOrclParm.sql\",\"ConnectionProfile\":\"ORACLE_CONNECTION_PROFILE\",\"Parameters\":[{\"firstParamName\":\"firstParamValue\"},{\"secondParamName\":\"secondParamValue\"}]}}}",
        "description": "The following example shows how to create a database job that runs a SQL script from a file system."
    },
    "Database SQL Script Basic": {
        "prefix": "jac.job.Database.SQL.Script.Basic",
        "body": "{\"MyOracleDBFolder\":{\"Type\":\"Folder\",\"testOracle\":{\"Type\":\"Job:Database:SQLScript\",\"Host\":\"app-redhat\",\"SQLScript\":\"/home/controlm/sqlscripts/selectOrclParm.sql\",\"ConnectionProfile\":\"ORACLE_CONNECTION_PROFILE\"}}}",
        "description": "The following example shows how to create a database job that runs a SQL script from a file system."
    },
    "Database Stored Procedure": {
        "prefix": "jac.job.Database.Stored.Procedure",
        "body": "{\"MystoreFolder\":{\"Type\":\"Folder\",\"jobStoredProcedure\":{\"Type\":\"Job:Database:StoredProcedure\",\"Host\":\"myhost.mycomp.com\",\"StoredProcedure\":\"myProcedure\",\"Parameters\":[\"value1\",\"variable1\",[\"value2\",\"variable2\"]],\"ReturnValue\":\"RV\",\"Schema\":\"public\",\"ConnectionProfile\":\"DB-PG-CON\"}}}",
        "description": "The following example shows how to create a database job that runs a program that is stored on the database."
    },
    "Database MSSQL Agent Job": {
        "prefix": "jac.job.Database.MSSQL.Agent.Job",
        "body": "{\"MyMSSQLFolder\":{\"Type\":\"Folder\",\"ControlmServer\":\"LocalControlM\",\"MSSQLAgentJob\":{\"Type\":\"Job:Database:MSSQL:AgentJob\",\"ConnectionProfile\":\"MSSQL-WE-EXAMPLE\",\"Host\":\"agentHost\",\"JobName\":\"get_version\",\"Category\":\"Data Collector\"}}}",
        "description": "The following example shows how to create an MSSQL Agent job, for management of a job defined in the SQL server."
    },
    "Database MSSQL SSIS": {
        "prefix": "jac.job.Database.MSSQL.SSIS",
        "body": "{\"MyMSSQLFolder\":{\"Type\":\"Folder\",\"ControlmServer\":\"LocalControlM\",\"SSISCatalog\":{\"Type\":\"Job:Database:MSSQL:SSIS\",\"ConnectionProfile\":\"MSSQL-CP-NAME\",\"Host\":\"agentHost\",\"PackageSource\":\"SSIS Catalog\",\"PackageName\":\"\\Data Collector\\SqlTraceCollect\",\"CatalogEnv\":\"ENV_NAME\",\"ConfigFiles\":[\"C:\\Users\\dbauser\\Desktop\\test.dtsConfig\",\"C:\\Users\\dbauser\\Desktop\\test2.dtsConfig\"],\"Properties\":[{\"PropertyName\":\"PropertyValue\"},{\"PropertyName2\":\"PropertyValue2\"}]},\"SSISPackageStore\":{\"Type\":\"Job:Database:MSSQL:SSIS\",\"ConnectionProfile\":\"MSSQL-CP-NAME\",\"Host\":\"agentHost\",\"PackageSource\":\"SSIS Package Store\",\"PackageName\":\"\\Data Collector\\SqlTraceCollect\",\"ConfigFiles\":[\"C:\\Users\\dbauser\\Desktop\\test.dtsConfig\",\"C:\\Users\\dbauser\\Desktop\\test2.dtsConfig\"],\"Properties\":[{\"PropertyName\":\"PropertyValue\"},{\"PropertyName2\":\"PropertyValue2\"}]}}}",
        "description": "The following example shows how to create SSIS Package jobs for execution of SQL Server Integration Services (SSIS) packages"
    },
    "Hadoop Spark Python Basic": {
        "prefix": "jac.job.Hadoop.Spark.Python.Basic",
        "body": "\"MyProcessData\":{\"Type\":\"Job:Hadoop:Spark:Python\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"DEV_CLUSTER\",\"SparkScript\":\"/home/user/processData.py\"}",
        "description": "The following example shows how to use Job:Hadoop:Spark:Python to run a Spark Python program."
    },
    "Hadoop Spark Python Advanced": {
        "prefix": "jac.job.Hadoop.Spark.Python.Advanced",
        "body": "\"MyProcessData\":{\"Type\":\"Job:Hadoop:Spark:Python\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"DEV_CLUSTER\",\"SparkScript\":\"/home/user/processData.py\",\"Arguments\":[\"1000\",\"120\"],\"PreCommands\":{\"FailJobOnCommandFailure\":false,\"Commands\":[{\"get\":\"hdfs://nn.example.com/user/hadoop/file localfile\"},{\"rm\":\"hdfs://nn.example.com/file /user/hadoop/emptydir\"}]},\"PostCommands\":{\"FailJobOnCommandFailure\":true,\"Commands\":[{\"put\":\"localfile hdfs://nn.example.com/user/hadoop/file\"}]},\"SparkOptions\":[{\"--master\":\"yarn\"},{\"--num\":\"-executors 50\"}]}",
        "description": "The following example shows how to use Job:Hadoop:Spark:Python to run a Spark Python program."
    },
    "Hadoop Spark Scala Java Basic": {
        "prefix": "jac.job.Hadoop.Spark.Scala.Java.Basic",
        "body": "\"MyProcessData\":{\"Type\":\"Job:Hadoop:Spark:ScalaJava\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"DEV_CLUSTER\",\"ProgramJar\":\"/home/user/ScalaProgram.jar\",\"MainClass\":\"com.mycomp.sparkScalaProgramName.mainClassName\"}",
        "description": "The following example shows how to use Job:Hadoop:Spark:ScalaJava to run a Spark Java or Scala program."
    },
    "Hadoop Spark Scala Java Advanced": {
        "prefix": "jac.job.Hadoop.Spark.Scala.Java.Advanced",
        "body": "\"MyProcessData\":{\"Type\":\"Job:Hadoop:Spark:ScalaJava\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"DEV_CLUSTER\",\"ProgramJar\":\"/home/user/ScalaProgram.jar\",\"MainClass\":\"com.mycomp.sparkScalaProgramName.mainClassName\",\"Arguments\":[\"1000\",\"120\"],\"PreCommands\":{\"FailJobOnCommandFailure\":false,\"Commands\":[{\"get\":\"hdfs://nn.example.com/user/hadoop/file localfile\"},{\"rm\":\"hdfs://nn.example.com/file /user/hadoop/emptydir\"}]},\"PostCommands\":{\"FailJobOnCommandFailure\":true,\"Commands\":[{\"put\":\"localfile hdfs://nn.example.com/user/hadoop/file\"}]},\"SparkOptions\":[{\"--master\":\"yarn\"},{\"--num\":\"-executors 50\"}]}",
        "description": "The following example shows how to use Job:Hadoop:Spark:ScalaJava to run a Spark Java or Scala program."
    },
    "Hadoop Pig Basic": {
        "prefix": "jac.job.Hadoop.Pig.Basic",
        "body": "\"MyProcessDataPig\":{\"Type\":\"Job:Hadoop:Pig\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"DEV_CLUSTER\",\"PigScript\":\"/home/user/script.pig\"}",
        "description": "The following example shows how to use Job:Hadoop:Pig to run a Pig script."
    },
    "Hadoop Pig Advanced": {
        "prefix": "jac.job.Hadoop.Pig.Advanced",
        "body": "\"MyProcessDataPig\":{\"Type\":\"Job:Hadoop:Pig\",\"ConnectionProfile\":\"DEV_CLUSTER\",\"PigScript\":\"/home/user/script.pig\",\"Host\":\"edgenode\",\"Parameters\":[{\"amount\":\"1000\"},{\"volume\":\"120\"}],\"PreCommands\":{\"FailJobOnCommandFailure\":false,\"Commands\":[{\"get\":\"hdfs://nn.example.com/user/hadoop/file localfile\"},{\"rm\":\"hdfs://nn.example.com/file /user/hadoop/emptydir\"}]},\"PostCommands\":{\"FailJobOnCommandFailure\":true,\"Commands\":[{\"put\":\"localfile hdfs://nn.example.com/user/hadoop/file\"}]}}",
        "description": "The following example shows how to use Job:Hadoop:Pig to run a Pig script."
    },
    "Hadoop Sqoop Basic": {
        "prefix": "jac.job.Hadoop.Sqoop.Basic",
        "body": "\"MyLoadDataSqoop\":{\"Type\":\"Job:Hadoop:Sqoop\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"SQOOP_CONNECTION_PROFILE\",\"SqoopCommand\":\"import --table foo --target-dir /dest_dir\"}",
        "description": "The following example shows how to use Job:Hadoop:Sqoop to run a Sqoop job."
    },
    "Hadoop Sqoop Advanced": {
        "prefix": "jac.job.Hadoop.Sqoop.Advanced",
        "body": "\"MyLoadDataSqoop\":{\"Type\":\"Job:Hadoop:Sqoop\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"SQOOP_CONNECTION_PROFILE\",\"SqoopCommand\":\"import --table foo\",\"SqoopOptions\":[{\"--warehouse-dir\":\"/shared\"},{\"--default-character-set\":\"latin1\"}],\"SqoopArchives\":\"\",\"SqoopFiles\":\"\",\"PreCommands\":{\"FailJobOnCommandFailure\":false,\"Commands\":[{\"get\":\"hdfs://nn.example.com/user/hadoop/file localfile\"},{\"rm\":\"hdfs://nn.example.com/file /user/hadoop/emptydir\"}]},\"PostCommands\":{\"FailJobOnCommandFailure\":true,\"Commands\":[{\"put\":\"localfile hdfs://nn.example.com/user/hadoop/file\"}]}}",
        "description": "The following example shows how to use Job:Hadoop:Sqoop to run a Sqoop job."
    },
    "Hadoop Hive Basic": {
        "prefix": "jac.job.Hadoop.Hive.Basic",
        "body": "\"MyProcessHive\":{\"Type\":\"Job:Hadoop:Hive\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"HIVE_CONNECTION_PROFILE\",\"HiveScript\":\"/home/user1/hive.script\"}",
        "description": "The following example shows how to use Job:Hadoop:Hive to run a Hive beeline job."
    },
    "Hadoop Hive Advanced": {
        "prefix": "jac.job.Hadoop.Hive.Advanced",
        "body": "\"MyProcessHive\":{\"Type\":\"Job:Hadoop:Hive\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"HIVE_CONNECTION_PROFILE\",\"HiveScript\":\"/home/user1/hive.script\",\"Parameters\":[{\"ammount\":\"1000\"},{\"topic\":\"food\"}],\"HiveArchives\":\"\",\"HiveFiles\":\"\",\"HiveOptions\":[{\"hive.root.logger\":\"INFO,console\"}],\"PreCommands\":{\"FailJobOnCommandFailure\":false,\"Commands\":[{\"get\":\"hdfs://nn.example.com/user/hadoop/file localfile\"},{\"rm\":\"hdfs://nn.example.com/file /user/hadoop/emptydir\"}]},\"PostCommands\":{\"FailJobOnCommandFailure\":true,\"Commands\":[{\"put\":\"localfile hdfs://nn.example.com/user/hadoop/file\"}]}}",
        "description": "The following example shows how to use Job:Hadoop:Hive to run a Hive beeline job."
    },
    "Hadoop Distributed Copy Basic": {
        "prefix": "jac.job.Hadoop.DistCp.Basic",
        "body": "\"MyDistCpJob\":{\"Type\":\"Job:Hadoop:DistCp\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"DEV_CLUSTER\",\"TargetPath\":\"hdfs://nns2:8020/foo/bar\",\"SourcePaths\":[\"hdfs://nn1:8020/foo/a\"]}",
        "description": "The following example shows how to use Job:Hadoop:DistCp to run a DistCp job.  DistCp (distributed copy) is a tool used for large inter/intra-cluster copying."
    },
    "Hadoop Distributed Copy Advanced": {
        "prefix": "jac.job.Hadoop.DistCp.Advanced",
        "body": "\"MyDistCpJob\":{\"Type\":\"Job:Hadoop:DistCp\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"HADOOP_CONNECTION_PROFILE\",\"TargetPath\":\"hdfs://nns2:8020/foo/bar\",\"SourcePaths\":[\"hdfs://nn1:8020/foo/a\",\"hdfs://nn1:8020/foo/b\"],\"DistcpOptions\":[{\"-m\":\"3\"},{\"-filelimit \":\"100\"}]}",
        "description": "The following example shows how to use Job:Hadoop:DistCp to run a DistCp job.  DistCp (distributed copy) is a tool used for large inter/intra-cluster copying."
    },
    "Hadoop HDFS Commands": {
        "prefix": "jac.job.Hadoop.HDFS.Commands",
        "body": "\"MyHdfsJob\":{\"Type\":\"Job:Hadoop:HDFSCommands\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"DEV_CLUSTER\",\"Commands\":[{\"get\":\"hdfs://nn.example.com/user/hadoop/file localfile\"},{\"rm\":\"hdfs://nn.example.com/file /user/hadoop/emptydir\"}]}",
        "description": "The following example shows how to use Job:Hadoop:HDFSCommands to run a job that executes one or more HDFS commands."
    },
    "Hadoop HDFS File Watcher": {
        "prefix": "jac.job.Hadoop.HDFS.File.Watcher",
        "body": "\"MyHdfsFileWatcherJob\":{\"Type\":\"Job:Hadoop:HDFSFileWatcher\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"DEV_CLUSTER\",\"HdfsFilePath\":\"/inputs/filename\",\"MinDetecedSize\":\"1\",\"MaxWaitTime\":\"2\"}",
        "description": "The following example shows how to use Job:Hadoop:HDFSFileWatcher to run a job that waits for HDFS file arrival."
    },
    "Hadoop Oozie": {
        "prefix": "jac.job.Hadoop.Oozie",
        "body": "\"MyOozieJob\":{\"Type\":\"Job:Hadoop:Oozie\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"DEV_CLUSTER\",\"JobPropertiesFile\":\"/home/user/job.properties\",\"OozieOptions\":[{\"inputDir\":\"/usr/tucu/inputdir\"},{\"outputDir\":\"/usr/tucu/outputdir\"}]}",
        "description": "The following example shows how to use Job:Hadoop:Oozie to run a job that submits an Oozie workflow."
    },
    "Hadoop MapReduce Basic": {
        "prefix": "jac.job.Hadoop.Map.Reduce.Basic",
        "body": "\"MyMapReduceJob\":{\"Type\":\"Job:Hadoop:MapReduce\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"DEV_CLUSTER\",\"ProgramJar\":\"/home/user1/hadoop-jobs/hadoop-mapreduce-examples.jar\",\"MainClass\":\"pi\",\"Arguments\":[\"1\",\"2\"]}",
        "description": "The following example shows how to use Job:Hadoop:MapReduce to execute a Hadoop MapReduce job."
    },
    "Hadoop MapReduce Advanced": {
        "prefix": "jac.job.Hadoop.Map.Reduce.Advanced",
        "body": "\"MyMapReduceJob\":{\"Type\":\"Job:Hadoop:MapReduce\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"DEV_CLUSTER\",\"ProgramJar\":\"/home/user1/hadoop-jobs/hadoop-mapreduce-examples.jar\",\"MainClass\":\"pi\",\"Arguments\":[\"1\",\"2\"],\"PreCommands\":{\"FailJobOnCommandFailure\":false,\"Commands\":[{\"get\":\"hdfs://nn.example.com/user/hadoop/file localfile\"},{\"rm\":\"hdfs://nn.example.com/file /user/hadoop/emptydir\"}]},\"PostCommands\":{\"FailJobOnCommandFailure\":true,\"Commands\":[{\"put\":\"localfile hdfs://nn.example.com/user/hadoop/file\"}]}}",
        "description": "The following example shows how to use Job:Hadoop:MapReduce to execute a Hadoop MapReduce job."
    },
    "Hadoop MapReduce Streaming": {
        "prefix": "jac.job.Hadoop.Map.Reduce.Streaming",
        "body": "\"MyMapredStreamingJob\":{\"Type\":\"Job:Hadoop:MapredStreaming\",\"Host\":\"edgenode\",\"ConnectionProfile\":\"DEV_CLUSTER\",\"InputPath\":\"/user/robot/input/*\",\"OutputPath\":\"/tmp/output\",\"MapperCommand\":\"mapper.py\",\"ReducerCommand\":\"reducer.py\",\"GeneralOptions\":[{\"-D\":\"fs.permissions.umask-mode=000\"},{\"-files\":\"/home/user/hadoop-streaming/mapper.py,/home/user/hadoop-streaming/reducer.py\"}]}",
        "description": "The following example shows how to use Job:Hadoop:MapredStreaming to execute a Hadoop MapReduce Streaming job."
    },
    "Hadoop Tajo InputFile": {
        "prefix": "jac.job.Hadoop.Tajo.InputFile",
        "body": "\"MyHadoopTajoInputFileJob\":{\"Type\":\"Job:Hadoop:Tajo:InputFile\",\"ConnectionProfile\":\"TAJO_CONNECTION_PROFILE\",\"Host\":\"edgenode\",\"FullFilePath\":\"/home/user/tajo_command.sh\",\"Parameters\":[{\"amount\":\"1000\"},{\"volume\":\"120\"}]}",
        "description": "The following example shows how to execute a Hadoop Tajo job based on an input file."
    },
    "Hadoop Tajo Query": {
        "prefix": "jac.job.Hadoop.Tajo.Query",
        "body": "\"MyHadoopTajoQueryJob\":{\"Type\":\"Job:Hadoop:Tajo:Query\",\"ConnectionProfile\":\"TAJO_CONNECTION_PROFILE\",\"Host\":\"edgenode\",\"OpenQuery\":\"SELECT %%firstParamName AS VAR1 \\n FROM DUMMY \\n ORDER BY \\t VAR1 DESC\"}",
        "description": "The following example shows how to execute a Hadoop Tajo job based on a query."
    },
    "SAP R3 Create Basic": {
        "prefix": "jac.job.SAP.R3.Create.Basic",
        "body": "\"MySapR3ExternalCommandJob\":{\"Type\":\"Job:SAP:R3:CREATE\",\"ConnectionProfile\":\"SAPCP\",\"SapJobName\":\"SAP_job\",\"CreatedBy\":\"user1\",\"Steps\":[{\"StepType\":\"ExternalCommand\",\"UserName\":\"user01\",\"TargetHost\":\"host01\",\"ProgramName\":\"PING\"}],\"SpoolListRecipient\":{\"ReciptNoForwarding\":false}}",
        "description": "This job type enables you to create a new SAP R3 job."
    },
    "SAP R3 Create Advanced": {
        "prefix": "jac.job.SAP.R3.Create.Advanced",
        "body": "\"MySapR3CreateCompleteJob\":{\"Type\":\"Job:SAP:R3:CREATE\",\"ConnectionProfile\":\"SAPCP\",\"SapJobName\":\"SAP_job2\",\"StartCondition\":\"Immediate\",\"RerunFromStep\":\"3\",\"Target\":\"controlmserver\",\"CreatedBy\":\"user1\",\"Steps\":[{\"StepType\":\"ABAP\",\"TimeToPrint\":\"PrintLater\",\"CoverPrintPage\":true,\"OutputDevice\":\"prt\",\"UserName\":\"user\",\"SpoolAuthorization\":\"Auth\",\"CoverDepartment\":\"dpt\",\"SpoolListName\":\"spoolname\",\"OutputNumberRows\":\"62\",\"NumberOfCopies\":\"5\",\"NewSpoolRequest\":false,\"PrintArchiveMode\":\"PrintAndArchive\",\"CoverPage\":\"Print\",\"ArchiveObjectType\":\"objtype\",\"SpoolListTitles\":\"titles\",\"OutputLayout\":\"layout\",\"CoverSheet\":\"Print\",\"ProgramName\":\"ABAP_PROGRAM\",\"Language\":\"e\",\"ArchiveInformationField\":\"inf\",\"DeleteAfterPrint\":true,\"PrintExpiration\":\"3\",\"OutputNumberColumns\":\"88\",\"ArchiveDocumentType\":\"doctype\",\"CoverRecipient\":\"recipient\",\"VariantName\":\"NameOfVariant\",\"VariantParameters\":[{\"Type\":\"Range\",\"High\":\"2\",\"Sign\":\"I\",\"Option\":\"BT\",\"Low\":\"1\",\"Name\":\"var1\",\"Modify\":false},{\"Low\":\"5\",\"Type\":\"Range\",\"Option\":\"BT\",\"Sign\":\"I\",\"Modify\":true,\"High\":\"6\",\"Name\":\"var3\"}]},{\"StepType\":\"ABAP\",\"PrintArchiveMode\":\"Print\",\"ProgramName\":\"ABAP_PROGRAM2\",\"VariantName\":\"Myvar_with_temp\",\"TemporaryVariantParameters\":[{\"Type\":\"Simple\",\"Name\":\"var\",\"Value\":\"P11\"},{\"Type\":\"Simple\",\"Name\":\"var2\",\"Value\":\"P11\"}]}],\"PostJobAction\":{\"Joblog\":\"CopyToFile\",\"JobCompletionStatusWillDependOnApplicationStatus\":true,\"SpoolSaveToPDF\":true,\"JoblogFile\":\"fileToCopy.txt\"},\"SpoolListRecipient\":{\"ReciptNoForwarding\":false}}",
        "description": "The following example is a more complex job that contains two steps that run ABAP programs. Each of the ABAP steps has an associated variant that contains variable definitions."
    },
    "SAP R3 Copy": {
        "prefix": "jac.job.SAP.R3.Copy",
        "body": "\"MySapR3CopyJob\":{\"Type\":\"Job:SAP:R3:COPY\",\"ConnectionProfile\":\"SAP-CON\",\"SapJobName\":\"CHILD_1\",\"Exec\":\"Server\",\"Target\":\"Server-name\",\"JobCount\":\"SpecificJob\",\"JobCountSpecificName\":\"sap-job-1234\",\"NewJobName\":\"My-New-Sap-Job\",\"StartCondition\":\"AfterEvent\",\"AfterEvent\":\"HOLA\",\"AfterEventParameters\":\"parm1 parm2\",\"RerunFromPointOfFailure\":true,\"CopyFromStep\":\"4\",\"PostJobAction\":{\"Spool\":\"CopyToFile\",\"SpoolFile\":\"spoolfile.log\",\"SpoolSaveToPDF\":true,\"JobLog\":\"CopyToFile\",\"JobLogFile\":\"Log.txt\",\"JobCompletionStatusWillDependOnApplicationStatus\":true},\"DetectSpawnedJob\":{\"DetectAndCreate\":\"SpecificJobDefinition\",\"JobName\":\"Specific-Job-123\",\"StartSpawnedJob\":true,\"JobEndInControlMOnlyAftreChildJobsCompleteOnSap\":true,\"JobCompletionStatusDependsOnChildJobsStatus\":true}}",
        "description": "This job type enables you to create a new SAP R3 job by duplicating an existing job. "
    },
    "SAP Business Warehouse Process Chain": {
        "prefix": "jac.job.SAP.BW.Process.Chain",
        "body": "\"MySapBWJob\":{\"Type\":\"Job:SAP:BW:ProcessChain\",\"ConnectionProfile\":\"PI4-BW\",\"ProcessChainDescription\":\"SAP BW Process Chain\",\"Id\":\"123456\",\"RerunOption\":\"RestartFromFailiurePoint\",\"EnablePeridoicJob\":true,\"ConsiderOnlyOverallChainStatus\":true,\"RetrieveLog\":false,\"DetectSpawnedJob\":{\"DetectAndCreate\":\"SpecificJobDefinition\",\"JobName\":\"ChildJob\",\"StartSpawnedJob\":false,\"JobEndInControlMOnlyAftreChildJobsCompleteOnSap\":false,\"JobCompletionStatusDependsOnChildJobsStatus\":false}}",
        "description": "This job type runs and monitors a Process Chain in SAP Business Warehouse (SAP BW)."
    },
    "SAP Business Warehouse Info Package": {
        "prefix": "jac.job.SAP.BW.Info.Package",
        "body": "\"MySapBWJob\":{\"Type\":\"Job:SAP:BW:InfoPackage\",\"ConnectionProfile\":\"PI4-BW\",\"CreatedBy\":\"emuser1\",\"Description\":\"description of the job\",\"RunAs\":\"ProductionUser\",\"InfoPackage\":{\"BackgroundJobName\":\"Background job name\",\"Description\":\"description of the InfoPackage\",\"TechName\":\"LGXT565_TGHBNS453BGHJ784\"}}",
        "description": "This job type runs and monitors an InfoPackage that is pre-defined in SAP Business Warehouse (SAP BW)."
    },
    "PeopleSoft": {
        "prefix": "jac.job.PeopleSoft",
        "body": "\"MyPeopleSoftJob\":{\"Type\":\"Job:PeopleSoft\",\"ConnectionProfile\":\"PS_CONNECT\",\"User\":\"PS_User3\",\"ControlId\":\"ControlId\",\"ServerName\":\"ServerName\",\"ProcessType\":\"ProcessType\",\"ProcessName\":\"ProcessName\",\"AppendToOutput\":false,\"BindVariables\":[\"value1\",\"value2\"],\"RunAs\":\"controlm\"}",
        "description": "The following example shows the JSON code used to define a PeopleSoft job."
    },
    "Application Integrator": {
        "prefix": "jac.job.Application.Integrator",
        "body": "\"MyAIJob\":{\"Type\":\"Job:ApplicationIntegrator:AI Monitor Remote Job\",\"ConnectionProfile\":\"AI_CONNECTION_PROFILE\",\"AI-Host\":\"Host1\",\"AI-Port\":\"5180\",\"AI-User Name\":\"admin\",\"AI-Password\":\"*******\",\"AI-Remote Job to Monitor\":\"remoteJob5\",\"RunAs\":\"controlm\"}",
        "description": "The following example shows the JSON code used to define a job type named AI Monitor Remote Job:"
    },
    "Informatica": {
        "prefix": "jac.job.Informatica",
        "body": "\"MyInformaticaJob\":{\"Type\":\"Job:Informatica\",\"ConnectionProfile\":\"INFORMATICA_CONNECTION\",\"RepositoryFolder\":\"POC\",\"Workflow\":\"WF_Test\",\"InstanceName\":\"MyInstamce\",\"OsProfile\":\"MyOSProfile\",\"WorkflowExecutionMode\":\"RunSingleTask\",\"RunSingleTask\":\"s_MapTest_Success\",\"WorkflowRestartMode\":\"ForceRestartFromSpecificTask\",\"RestartFromTask\":\"s_MapTest_Success\",\"WorkflowParametersFile\":\"/opt/wf1.prop\"}",
        "description": "The following example shows the JSON code used to define an Informatica job."
    },
    "Informatica Cloud Services Basic": {
        "prefix": "jac.job.Informatica.CS.Basic",
        "body": "\"MyInformaticaCloudCSJob\":{\"Type\":\"Job:Informatica CS\",\"ConnectionProfile\":\"INFORMATICA_CS_CONNECTION\",\"Task Type\":\"Synchronization task\",\"Task Name\":\"Synchronization Task1\",\"Call Back URL\":\"\",\"Verification Poll Interval (in seconds)\":\"10\"}",
        "description": "The following example shows the JSON code used to define an Informatica CS job"
    },
    "Informatica Cloud Services Taskflow": {
        "prefix": "jac.job.Informatica.CS.Taskflow",
        "body": "\"MyInformaticaCloudCSJob\":{\"Type\":\"Job:Informatica CS\",\"ConnectionProfile\":\"INFORMATICA_CS_CONNECTION\",\"Task Type\":\"Taskflow\",\"TaskFlow URL\":\"https://xxx.dm-xx.informaticacloud.com/active-bpel/rt/xyz\",\"Input Fields\":\"input1=val1&input2=val2&input3=val3\",\"Call Back URL\":\"\",\"Verification Poll Interval (in seconds)\":\"10\"}",
        "description": "The following example shows the JSON code used to define an Informatica CS job for a taskflow"
    },
    "AWS Lambda": {
        "prefix": "jac.job.AWS.Lambda",
        "body": "\"MyAwsLambdaJob\":{\"Type\":\"Job:AWS:Lambda\",\"ConnectionProfile\":\"AWS_CONNECTION\",\"FunctionName\":\"LambdaFunction\",\"Version\":\"1\",\"Payload\":\"{\\\"myVar\\\" :\\\"value1\\\" \\n\\\"myOtherVar\\\" : \\\"value2\\\"}\",\"AppendLog\":true}",
        "description": "The following example shows how to define a job that executes an AWS Lambda service on an AWS server."
    },
    "AWS Step Function": {
        "prefix": "jac.job.AWS.Step.Function",
        "body": "\"MyAwsStepFunctionJob\":{\"Type\":\"Job:AWS:StepFunction\",\"ConnectionProfile\":\"AWS_CONNECTION\",\"StateMachine\":\"StateMachine1\",\"ExecutionName\":\"Execution1\",\"Input\":\"{\\\"myVar\\\" :\\\"value1\\\" \\n\\\"myOtherVar\\\" : \\\"value2\\\"}\",\"AppendLog\":true}",
        "description": "The following example shows how to define a job that executes an AWS Step Function service on an AWS server."
    },
    "AWS Batch": {
        "prefix": "jac.job.AWS.Batch",
        "body": "\"MyAwsBatchJob\":{\"Type\":\"Job:AWS:Batch\",\"ConnectionProfile\":\"AWS_CONNECTION\",\"JobName\":\"batchjob1\",\"JobDefinition\":\"jobDef1\",\"JobDefinitionRevision\":\"3\",\"JobQueue\":\"queue1\",\"AWSJobType\":\"Array\",\"ArraySize\":\"100\",\"DependsOn\":{\"DependencyType\":\"Standard\",\"JobDependsOn\":\"job5\"},\"Command\":[\"ffmpeg\",\"-i\"],\"Memory\":\"10\",\"vCPUs\":\"2\",\"JobAttempts\":\"5\",\"ExecutionTimeout\":\"60\",\"AppendLog\":false}",
        "description": "The following example shows how to define a job that executes an AWS Batch service on an AWS server."
    },
    "AWS Glue": {
        "prefix": "jac.job.AWS.Glue",
        "body": "\"MyAwsGlueJob\":{\"Type\":\"Job:AWS Glue\",\"ConnectionProfile\":\"GLUECONNECTION\",\"AI-Glue Job Name\":\"AwsGlueJobName\",\"AI-Glue Job Arguments\":\"checked\",\"AI-Arguments\":\"{\\\"--myArg1\\\": \\\"myVal1\\\", \\\"--myArg2\\\": \\\"myVal2\\\"}\",\"AI-Status Polling Frequency\":\"20\"}",
        "description": "The following example shows how to define a job that executes Amazon Web Services (AWS) Glue, a serverless data integration service."
    },
    "Azure Function": {
        "prefix": "jac.job.Azure.Function",
        "body": "\"MyAzureFunctionJob\":{\"Type\":\"Job:Azure:Function\",\"ConnectionProfile\":\"AZURE_CONNECTION\",\"AppendLog\":false,\"Function\":\"AzureFunction\",\"FunctionApp\":\"AzureFunctionApp\",\"Parameters\":[{\"firstParamName\":\"firstParamValue\"},{\"secondParamName\":\"secondParamValue\"}]}",
        "description": "The following example shows how to define a job that executes an Azure function service."
    },
    "Azure Logic Apps": {
        "prefix": "jac.job.Azure.Logic.Apps",
        "body": "\"MyAzureLogicAppJob\":{\"Type\":\"Job:Azure:logicApps\",\"ConnectionProfile\":\"AZURE_CONNECTION\",\"logicAppName\":\"MylogicApp\",\"RequestBody\":\"{\\n  \\\"name\\\": \\\"BMC\\\"\\n}\",\"AppendLog\":false}",
        "description": "The following example shows how to define a job that executes an Azure logic App service."
    },
    "Azure Batch Account": {
        "prefix": "jac.job.Azure.Batch.Account",
        "body": "\"MyAzureBatchJob\":{\"Type\":\"Job:Azure:BatchAccount\",\"ConnectionProfile\":\"AZURE_CONNECTION\",\"JobId\":\"AzureJob1\",\"CommandLine\":\"echo \\\"Hello\\\"\",\"AppendLog\":false,\"Wallclock\":{\"Time\":\"770\",\"Unit\":\"Minutes\"},\"MaxTries\":{\"Count\":\"6\",\"Option\":\"Custom\"},\"Retention\":{\"Time\":\"1\",\"Unit\":\"Hours\"}}",
        "description": "The following example shows how to define a job that executes an Azure Batch Account service."
    },
    "Azure Data Factory": {
        "prefix": "jac.job.Azure.DF",
        "body": "\"MyAzureDataFactoryJob\":{\"Type\":\"Job:ADF\",\"ConnectionProfile\":\"DataFactoryConnection\",\"AI-Resource Group Name\":\"AzureResourceGroupName\",\"AI-Data Factory Name\":\"AzureDataFactoryName\",\"AI-Pipeline Name\":\"AzureDataFactoryPipelineName\",\"AI-Parameters\":\"{\\\"myVar\\\":\\\"value1\\\", \\\"myOtherVar\\\": \\\"value2\\\"}\",\"AI-Status Polling Frequency\":\"20\"}",
        "description": "The following example shows how to define a job that executes an Azure Data Factory (ADF) service."
    },
    "Azure Databricks": {
        "prefix": "jac.job.Azure.Databricks",
        "body": "\"MyAzureDatabricksNotebook\":{\"Type\":\"Job:Azure Databricks\",\"ConnectionProfile\":\"AZURE_DATABRICKS\",\"Databricks Job ID\":\"65\",\"Parameters\":\"{\\\"param1\\\":\\\"val1\\\", \\\"param2\\\":\\\"val2\\\"}\",\"Status Polling Frequency\":\"30\"}",
        "description": "The following example shows how to define a job that executes the Azure Databricks service."
    },
    "Azure Functions": {
        "prefix": "jac.job.Azure.Functions",
        "body": "\"MyAzureFunction\":{\"Type\":\"Job:AzureFunction\",\"ConnectionProfile\":\"AZUREFUNCTIONS\",\"Function App\":\"new-function\",\"Function Name\":\"Hello\",\"Optional Input Parameters\":\"\\\"{\\\"param1\\\":\\\"val1\\\", \\\"param2\\\":\\\"val2\\\"}\\\"\"}",
        "description": "The following example shows how to define a job that executes a cloud-based Azure Function for serverless application development."
    },
    "WebServices Input Parameters": {
        "prefix": "jac.job.WebServices.Input.Paremeters",
        "body": "\"MyWebServicesJob\":{\"Type\":\"Job:WebServices\",\"Location\":\"http://www.dneonline.com/calculator.asmx?WSDL\",\"SoapHeaderFile\":\"/home/myheader.txt\",\"Service\":\"Calculator(Port:CalculatorSoap)\",\"Operation\":\"Add\",\"RequestType\":\"Parameter\",\"OverrideUrlEndpoint\":\"http://myoverridehost.com\",\"OverrideContentType\":\"*/*\",\"HttpConnectionTimeout\":\"2345\",\"PreemptiveHttpAuthentication\":\"abc@bmc.com\",\"IncludeTitleInOutput\":true,\"ExcludeJobOutput\":false,\"ConnectionProfile\":\"CALCULATOR\",\"Host\":\"host1\",\"OutputParameters\":[{\"Element\":\"AddResponse.AddResult\",\"HttpCode\":\"*\",\"Destination\":\"testResultAdd\",\"Type\":\"string\"}],\"InputParameters\":[{\"Name\":\"Add.intA\",\"Value\":\"97\",\"Type\":\"string\"},{\"Name\":\"Add.intB\",\"Value\":\"345\",\"Type\":\"string\"}]}",
        "description": "The following example presents a Web Services job that receives input for a calculator service and outputs the result of a simple calculation"
    },
    "WebServices Input File": {
        "prefix": "jac.job.WebServices.Input.File",
        "body": "\"MyWSSoapRequestInputFileJob\":{\"Type\":\"Job:WebServices\",\"SoapHeaderFile\":\"/home/myheader.txt\",\"Location\":\"http://www.dneonline.com/calculator.asmx?WSDL\",\"Service\":\"Calculator(Port:CalculatorSoap)\",\"Operation\":\"Add\",\"RequestType\":\"InputFile\",\"OverrideUrlEndpoint\":\"http://myoverridehost.com\",\"OverrideContentType\":\"*/*\",\"HttpConnectionTimeout\":\"2345\",\"PreemptiveHttpAuthentication\":\"abc@bmc.com\",\"IncludeTitleInOutput\":true,\"ExcludeJobOutput\":false,\"ConnectionProfile\":\"CALCULATOR\",\"Host\":\"host1\",\"OutputParameters\":[{\"Element\":\"AddResponse.AddResult\",\"HttpCode\":\"*\",\"Destination\":\"testResultAdd\",\"Type\":\"string\"}],\"InputFile\":\"/home/usr/soap.xml\"}",
        "description": "The following example presents a Web Services job that receives a SOAP request thorugh an input file. "
    },
    "WebServices REST Service": {
        "prefix": "jac.job.WebServices.REST",
        "body": "\"MyRESTServiceJob\":{\"Type\":\"Job:WebServices\",\"Location\":\"http://www.dneonline.com\",\"Service\":\"/restAPI/calculator.asmx\",\"Operation\":\"PUT\",\"RequestType\":\"Parameter\",\"OverrideContentType\":\"*/*\",\"HttpConnectionTimeout\":\"2345\",\"PreemptiveHttpAuthentication\":\"abc@bmc.com\",\"IncludeTitleInOutput\":true,\"ExcludeJobOutput\":false,\"ConnectionProfile\":\"CALCULATOR_REST\",\"Host\":\"host1\",\"OutputParameters\":[{\"Element\":\"$AddResponse.AddResult\",\"HttpCode\":\"*\",\"Destination\":\"testResultAdd\",\"Type\":\"string\"}],\"InputParameters\":[{\"Name\":\"intA\",\"Value\":\"97\",\"Type\":\"string\"},{\"Name\":\"intB\",\"Value\":\"345\",\"Type\":\"string\"},{\"Name\":\"accept-encoding\",\"Value\":\"*/*\",\"Type\":\"header\"}]}",
        "description": "The following example presents a job that receives input for a calculator REST service and outputs the result of a simple calculation."
    },
    "SLA Management": {
        "prefix": "jac.job.SLA.Management",
        "body": "{\"MySLARobotTestFolderGood\":{\"Type\":\"SimpleFolder\",\"ControlmServer\":\"LocalControlM\",\"Hello\":{\"Type\":\"Job:Command\",\"CreatedBy\":\"emuser\",\"RunAs\":\"controlm\",\"Command\":\"echo \\\"Hello\\\"\",\"eventsToAdd\":{\"Type\":\"AddEvents\",\"Events\":[{\"Event\":\"Hello-TO-SLA_Job_for_SLA-GOOD\"}]}},\"SLA\":{\"Type\":\"Job:SLAManagement\",\"ServiceName\":\"SLA-GOOD\",\"ServicePriority\":\"1\",\"CreatedBy\":\"emuser\",\"RunAs\":\"DUMMYUSR\",\"JobRunsDeviationsTolerance\":\"2\",\"CompleteIn\":{\"Time\":\"00:01\"},\"eventsToWaitFor\":{\"Type\":\"WaitForEvents\",\"Events\":[{\"Event\":\"Hello-TO-SLA_Job_for_SLA-GOOD\"}]},\"eventsToDelete\":{\"Type\":\"DeleteEvents\",\"Events\":[{\"Event\":\"Hello-TO-SLA_Job_for_SLA-GOOD\"}]}}}}",
        "description": "SLA Management jobs enable you to identify a chain of jobs that comprise a critical service and must complete by a certain time."
    },
    "SLA Management Service Action": {
        "prefix": "jac.job.SLA.Management.Service.Action",
        "body": "\"MyServiceActions\":{\"If:SLA:ServiceIsLate_0\":{\"Type\":\"If:SLA:ServiceIsLate\",\"Action:SLA:Notify_0\":{\"Type\":\"Action:SLA:Notify\",\"Severity\":\"Regular\",\"Message\":\"this is a message\"},\"Action:SLA:Mail_1\":{\"Type\":\"Action:SLA:Mail\",\"Email\":\"email@okmail.com\",\"Subject\":\"this is a subject\",\"Message\":\"this is a message\"},\"If:SLA:JobFailureOnServicePath_1\":{\"Type\":\"If:SLA:JobFailureOnServicePath\",\"Action:SLA:Order_0\":{\"Type\":\"Action:SLA:Order\",\"Server\":\"LocalControlM\",\"Folder\":\"folder\",\"Job\":\"job\",\"Date\":\"OrderDate\",\"Library\":\"library\"}},\"If:SLA:ServiceEndedNotOK_5\":{\"Type\":\"If:SLA:ServiceEndedNotOK\",\"Action:SLA:Set_0\":{\"Type\":\"Action:SLA:Set\",\"Variable\":\"varname\",\"Value\":\"varvalue\"},\"Action:SLA:Increase_2\":{\"Type\":\"Action:SLA:Increase\",\"Time\":\"04:03\"}},\"If:SLA:ServiceLatePastDeadline_6\":{\"Type\":\"If:SLA:ServiceLatePastDeadline\",\"Action:SLA:Event:Add_0\":{\"Type\":\"Action:SLA:Event:Add\",\"Server\":\"LocalControlM\",\"Name\":\"addddd\",\"Date\":\"AnyDate\"}}}}",
        "description": "The following example demonstrates a series of Service Actions that are triggered in response to specific occurrences (If statements)."
    },
    "UI Path": {
        "prefix": "jac.job.UI.Path",
        "body": "\"MyUIPathJob\":{\"Type\":\"Job:UI Path\",\"ConnectionProfile\":\"UIPATH_Connect\",\"Folder Name\":\"Default\",\"Folder Id\":\"374999\",\"Process Name\":\"control-m-process\",\"packagekey\":\"209c467e-1704-4b6y-b613-6c5a2c9acbea\",\"Robot Name\":\"abc-ctm-bot\",\"Robot Id\":\"153999\",\"Optional Input Parameters\":{\"parm1\":\"Value1\",\"parm2\":\"Value2\",\"parm3\":\"Value3\"},\"Status Polling Frequency\":\"30\",\"Host\":\"host1\"}",
        "description": "The following example shows how to define a UiPath job, which performs robotic process automation (RPA)."
    },
    "Google DataFlow": {
        "prefix": "jac.job.Google.Data.Flow",
        "body": "\"MyGoogleDataFlowJob\":{\"Type\":\"Job:Google DataFlow\",\"ConnectionProfile\":\"GCPDATAFLOW\",\"Project ID\":\"applied-lattice-11111\",\"Location\":\"us-central1\",\"Template Type\":\"Classic Template\",\"Template Location (gs://)\":\"gs://dataflow-templates-us-central1/latest/Word_Count\",\"Parameters (JSON Format)\":{\"jobName\":\"wordcount\",\"parameters\":{\"inputFile\":\"gs://dataflow-samples/shakespeare/kinglear.txt\",\"output\":\"gs://controlmbucket/counts\"}},\"Verification Poll Interval (in seconds)\":\"10\",\"Log Level\":\"INFO\",\"Host\":\"host1\"}",
        "description": "The following example shows how to define a Google Dataflow job, which performs cloud-based  data processing for batch and real-time data streaming applications. The following example shows a job for a Dataproc task of type Workflow Template."
    },
    "Google DataProc Workflow Template": {
        "prefix": "jac.job.Google.Data.Proc.Workflow",
        "body": "\"MyGoogleDataprocJob\":{\"Type\":\"Job:Google Dataproc\",\"ConnectionProfile\":\"GCPDATAPROC\",\"Project ID\":\"applied-lattice-11111\",\"Account Region\":\"us-central1\",\"Dataproc task type\":\"Workflow Template\",\"Workflow Template\":\"Template2\",\"Parameters (JSON Format)\":{},\"Verification Poll Interval (in seconds)\":\"10\",\"Host\":\"host1\"}",
        "description": "The following examples show how to define a Google Dataproc job, which performs cloud-based big data processing and machine learning."
    },
    "Google DataProc Job": {
        "prefix": "jac.job.Google.Data.Proc.Job",
        "body": "\"MyGoogleDataprocJob\":{\"Type\":\"Job:Google Dataproc\",\"ConnectionProfile\":\"GCPDATAPROC\",\"Project ID\":\"applied-lattice-11111\",\"Account Region\":\"us-central1\",\"Dataproc task type\":\"Job\",\"Parameters (JSON Format)\":{\"job\":{\"placement\":{},\"statusHistory\":[],\"reference\":{\"jobId\":\"job-e241f6be\",\"projectId\":\"applied-lattice-333108\"},\"labels\":{\"goog-dataproc-workflow-instance-id\":\"44f2b59b-a303-4e57-82e5-e1838019a812\",\"goog-dataproc-workflow-template-id\":\"template-d0a7c\"},\"sparkJob\":{\"mainClass\":\"org.apache.spark.examples.SparkPi\",\"properties\":{},\"jarFileUris\":[\"file:///usr/lib/spark/examples/jars/spark-examples.jar\"],\"args\":[\"1000\"]}}},\"Verification Poll Interval (in seconds)\":\"10\",\"Host\":\"host1\"}",
        "description": "The following examples show how to define a Google Dataproc job, which performs cloud-based big data processing and machine learning. The following example shows a job for a Dataproc task of type Job."
    },
    "Boomi": {
        "prefix": "jac.job.Boomi",
        "body": "\"MyBoomiJob\":{\"Type\":\"Job:Boomi\",\"ConnectionProfile\":\"BOOMI_CCP\",\"Atom Name\":\"Atom1\",\"Process Name\":\"New Process\",\"Polling Intervals\":\"20\",\"Tolerance\":\"3\"}",
        "description": "The following example shows how to define a Boomi job, which enables the integration of Boomi processes with your existing Control-M workflows."
    },
    "Databricks": {
        "prefix": "jac.job.Databricks",
        "body": "\"MyDatabricksJob\":{\"Type\":\"Job:Databricks\",\"ConnectionProfile\":\"DATABRICKS\",\"Databricks Job ID\":\"91\",\"Parameters\":\"{\\\"param1\\\":\\\"val1\\\", \\\"param2\\\":\\\"val2\\\"}\",\"Status Polling Frequency\":\"30\"}",
        "description": "The following example shows how to define a Databricksjob, which enables the integration of jobs created in the Databricks environment with your existing Control-M workflows."
    },
    "Microsoft Power BI": {
        "prefix": "jac.job.Microsoft.Power.BI",
        "body": "\"MyMicrosoftPowerBIJob\":{\"Type\":\"Job:Microsoft Power BI\",\"ConnectionProfile\":\"POWERBI\",\"Group Name\":\"Demo\",\"Group ID\":\"a7989345-8cfe-44e7-851d-81560e67973f\",\"Dataset Name(Optional)\":\"Demo_Dataset\",\"Pipeline ID(Optional)\":\"83f36385-4e38-43g4-8263-10aa12e3175c\"}",
        "description": "The following example shows how to define a Power BI job, which enables integration of Power BI workflows with your existing Control-M workflows."
    },
    "Dummy": {
        "prefix": "jac.job.Dummy",
        "body": "\"MyDummyJob\":{\"Type\":\"Job:Dummy\"}",
        "description": "The following example shows how to use Job:Dummy to define a job that always ends successfully without running any commands. "
    },
    "zOS Member": {
        "prefix": "jac.job.zOS.Member",
        "body": "{\"MyZFFolder\":{\"Type\":\"Folder\",\"ControlmServer\":\"M2MTROLM\",\"FolderLibrary\":\"IOAA.CCIDM2.CTM.OPR.SCHEDULE\",\"RunAs\":\"emuser\",\"CreatedBy\":\"emuser\",\"When\":{\"RuleBasedCalendars\":{\"Included\":[\"EVERYDAY\"],\"EVERYDAY\":{\"Type\":\"Calendar:RuleBased\",\"When\":{\"DaysRelation\":\"OR\",\"WeekDays\":[\"NONE\"],\"MonthDays\":[\"ALL\"]}}}},\"ZJ_DATA\":{\"Type\":\"Job:zOS:Member\",\"SystemAffinity\":\"ABCD\",\"SchedulingEnvironment\":\"PLEX8ALL\",\"ControlDCategory\":\"SEQL_FILE\",\"PreventNCT2\":\"Yes\",\"MemberLibrary\":\"IOA.WORK.JCL\",\"SAC\":\"Prev\",\"CreatedBy\":\"emuser\",\"RequestNJENode\":\"NODE3\",\"RunAs\":\"emuser\",\"StatisticsCalendar\":\"CALPERIO\",\"TaskInformation\":{\"EmergencyJob\":true,\"RunAsStartedTask\":true},\"OutputHandling\":{\"Operation\":\"Copy\",\"FromClass\":\"X\",\"Destination\":\"NODE3\"},\"History\":{\"RetentionDays\":\"05\",\"RetentionGenerations\":\"07\"},\"Archiving\":{\"JobRunsToRetainData\":\"4\",\"DaysToRetainData\":\"1\",\"ArchiveSysData\":true},\"Scheduling\":{\"MinimumNumberOfTracks\":\"5\",\"PartitionDataSet\":\"fgf\"},\"RerunLimit\":{\"RerunMember\":\"JOBRETRY\",\"Units\":\"Minutes\",\"Every\":\"7\"},\"MustEnd\":{\"Minutes\":\"16\",\"Hours\":\"17\",\"Days\":\"0\"},\"When\":{\"WeekDays\":[\"NONE\"],\"Months\":[\"NONE\"],\"MonthDays\":[\"NONE\"],\"DaysRelation\":\"OR\"},\"CRS\":{\"Type\":\"Resource:Lock\",\"IfFail\":\"Keep\",\"LockType\":\"Shared\"},\"QRS\":{\"Type\":\"Resource:Pool\",\"IfFail\":\"Keep\",\"IfOk\":\"Discard\",\"Quantity\":\"1\"},\"Demo\":{\"Type\":\"StepRange\",\"FromProgram\":\"STEP1\",\"FromProcedure\":\"SMPIOA\",\"ToProgram\":\"STEP8\",\"ToProcedure\":\"CTBTROLB\"},\"IfCollection:zOS_0\":{\"Type\":\"IfCollection:zOS\",\"Ifs\":[{\"Type\":\"If:zOS:AnyProgramStep\",\"ReturnCodes\":[\"OK\"],\"Procedure\":\"SMPIOA\"},\"OR\",{\"Type\":\"If:zOS:EveryProgramStep\",\"ReturnCodes\":[\"*$EJ\",\">S002\"],\"Procedure\":\"SMPIOA\"}],\"CtbRuleData_2\":{\"Type\":\"Action:ControlMAnalyzerRule\",\"Name\":\"RULEDEMO\",\"Arg\":\"3\"}},\"IfCollection:zOS_1\":{\"Type\":\"IfCollection:zOS\",\"Ifs\":[{\"Type\":\"If:zOS:SpecificProgramStep\",\"Program\":\"Demo\",\"ReturnCodes\":[\"*****\"],\"Procedure\":\"SMPIOA\"},\"OR\",{\"Type\":\"If:zOS:SpecificProgramStep\",\"Program\":\"STEP5\",\"ReturnCodes\":[\">U0002\"],\"Procedure\":\"SMPIOA\"}],\"IfRerun_2\":{\"Type\":\"Action:Restart\",\"FromProgram\":\"STEP1\",\"FromProcedure\":\"SMPIOA\",\"ToProgram\":\"STEP5\",\"ToProcedure\":\"CTBTROLB\",\"Confirm\":false}}}}}",
        "description": ""
    },
    "zOS In-Stream JCL": {
        "prefix": "jac.job.zOS.InStream.JCL",
        "body": "\"MyZFJcLFolder\":{\"Type\":\"SimpleFolder\",\"ControlmServer\":\"R2MTROLM\",\"FolderLibrary\":\"CTMP.V900.SCHEDULE\",\"OrderMethod\":\"Manual\",\"Z_R1\":{\"Type\":\"Job:zOS:InStreamJCL\",\"JCL\":\"0036//ROASMCL JOB ,ASM,CLASS=A,REGION=0M0033// JCLLIB ORDER=IOAP.V900.PROCLIB0024// INCLUDE MEMBER=IOASET0035//S1 EXEC IOATEST,PARM='TERM=C0000'0035//S2 EXEC IOATEST,PARM='TERM=C0000'\",\"CreatedBy\":\"emuser\",\"RunAs\":\"emuser\",\"When\":{\"WeekDays\":[\"NONE\"],\"MonthDays\":[\"ALL\"],\"DaysRelation\":\"OR\"},\"Archiving\":{\"ArchiveSysData\":true}}}",
        "description": "The following example shows how to create an in-stream JCL job which runs an embedded script on a z/OS system."
    },
    "Azure Blob Copy Blob Job": {
        "prefix": "jac.job.Azure.Blob.Copy.Blob",
        "body": "\"MyAzureBlobCopyBlob\": {\"Type\": \"Job:ApplicationIntegrator:AI Azure Blob Storage\",\"ConnectionProfile\": \"<CONNECTION_PROFILE NAME>\",\"AI-Action\": \"Copy\",\"AI-Source-uri\": \"<AZURE SOURCE-URI FOR SOURCE BLOB>\",\"AI-Destination container\": \"<AZURE BLOB CONTAINER NAME>\",\"AI-Destination blob name\": \"<AZURE BLOB BLOB NAME>\"",
        "description": "Job that copies a blob from one container to another"
    },
    "Azure Blob Create Container Job": {
        "prefix": "jac.job.Azure.Blob.Create.Container",
        "body": "\"MyAzureBlobCreateContainer\": {\"Type\": \"Job:ApplicationIntegrator:AI Azure Blob Storage\",\"ConnectionProfile\": \"<CONNECTION_PROFILE NAME>\",\"AI-Action\": \"Create container\",\"AI-Container (Create/Delete)\": \"<AZURE BLOB CONTAINER NAME>\",\"AI-Public Access\": \"Off\"",
        "description": "Job that creates a new Azure blob container"
    },
    "Azure Blob Delete Blob Job": {
        "prefix": "jac.job.Azure.Blob.Delete.Blob",
        "body": "\"MyAzureBlobDeleteBlob\": {\"Type\": \"Job:ApplicationIntegrator:AI Azure Blob Storage\",\"ConnectionProfile\": \"<CONNECTION_PROFILE NAME>\",\"AI-Action\": \"Delete\",\"AI-Container (Delete)\": \"<AZURE BLOB CONTAINER NAME>\",\"AI-Blob name (Delete)\": \"<BLOB_NAME>\"",
        "description": "Job that deletes a blob from a container"
    },
    "Azure Blob Delete Container Job": {
        "prefix": "jac.job.Azure.Blob.Delete.Container",
        "body": "\"MyAzureBlobDeleteContainer\": {\"Type\": \"Job:ApplicationIntegrator:AI Azure Blob Storage\",\"ConnectionProfile\": \"<CONNECTION_PROFILE NAME>\",\"AI-Action\": \"Delete container\",\"AI-Container (Create/Delete)\": \"<AZURE BLOB CONTAINER NAME>\"",
        "description": "Job that deletes a contianer including any blobs inside"
    },
    "Azure Blob Download Job": {
        "prefix": "jac.job.Azure.Blob.Download",
        "body": "\"MyAzureBlobDownloadBlob\": {\"Type\": \"Job:ApplicationIntegrator:AI Azure Blob Storage\",\"ConnectionProfile\": \"<CONNECTION_PROFILE NAME>\",\"AI-Action\": \"Download\",\"AI-Container (Up/Download)\": \"<AZURE BLOB CONTAINER NAME>\",\"AI-Blob name (Up/Download)\": \"<BLOB_NAME>\",\"AI-File path\": \"<PATH TO FILE ON AGENT FILE SYSTEM>\"",
        "description": "Job that uploads a file into a azure blob"
    },
    "Azure Blob List Files Job": {
        "prefix": "jac.job.Azure.Blob.List.Files",
        "body": "\"MyAzureBlobListBlobs\": {\"Type\": \"Job:ApplicationIntegrator:AI Azure Blob Storage\",\"ConnectionProfile\": \"<CONNECTION_PROFILE NAME>\",\"AI-Action\": \"List\",\"AI-Output\": \"table\",\"AI-Container (List)\": \"<AZURE BLOB CONTAINER NAME>\"",
        "description": "List blobs in a container"
    },
    "Azure Blob Upload Job": {
        "prefix": "jac.job.Azure.Blob.Upload",
        "body": "\"MyAzureBlobUploadBlob\": {\"Type\": \"Job:ApplicationIntegrator:AI Azure Blob Storage\",\"ConnectionProfile\": \"<CONNECTION_PROFILE NAME>\",\"AI-Action\": \"Upload\",\"AI-Container (Up/Download)\": \"<AZURE BLOB CONTAINER NAME>\",\"AI-Blob name (Up/Download)\": \"<BLOB_NAME>\",\"AI-File path\": \"<PATH TO FILE ON AGENT FILE SYSTEM>\"",
        "description": "Job that uploads a file into a azure blob"
    },
    "Run Oder Job Config": {
        "prefix": "jac.run.order.config.basic",
        "body": "{\"variables\": [{\"arg\": \"1234\"},{\"arg2\": \"abcd\"},{\"arg3\": \"0000\"}],\"ignoreCriteria\": \"true\",\"orderIntoFolder\": \"Recent\",\"orderDate\": \"20170903\",\"waitForOrderDate\": \"false\",\"hold\": \"true\"}",
        "description": "Order a folder or job with configuration file"
    },
    "ReRun Oder zOS Job Config": {
        "prefix": "jac.run.order.config.rerun",
        "body": "{\"zosParameters\": {\"from\": {\"pgmstep\": \"INPROCS2\",\"procstep\": \"STEP1\"},\"to\": {\"pgmstep\": \"INPROCS3\",\"procstep\": \"STEP2\"},\"cleanup\": true,\"recaptureAbend\": \"Y\",\"recaptureConditionCode\": \"N\",\"stepAdjustment\": true,\"restartParmMemberName\": \"IDJOB5\"}}",
        "description": "ReRun a folder or job with configuration file"
    },
    "Workload Policy Advanced": {
        "prefix": "jac.run.workload.policy.advanced",
        "body": "{\"Workload_Policy\":{\"Type\":\"WorkloadPolicy\",\"Description\":\"My Workload Policy\",\"Filter\":{\"Folder\":\"Folder5\",\"Server\":\"LocalControlM\",\"Application\":\"app3\",\"SubApplication\":\"subapp7\",\"JobName\":\"MyJob\",\"Host\":\"host1\"},\"RunningJobs\":[{\"Server\":\"LocalControlM\",\"Quantity\":\"5\",\"RangeDates\":{\"ToDate\":\"20210711\",\"FromDate\":\"20210711\"},\"SpecificTime\":{\"ToTime\":\"1130\",\"FromTime\":\"1030\"}},{\"Server\":\"Global\",\"Quantity\":\"3\",\"PeriodicDays\":{\"DaysOfWeek\":[\"WED\",\"FRI\"]},\"SpecificTime\":{\"ToTime\":\"1100\",\"FromTime\":\"1000\"}}],\"ResourcePools\":[{\"Server\":\"LocalControlM\",\"Resource\":\"pool1\",\"Quantity\":\"2\",\"PeriodicDays\":{\"DaysOfWeek\":[\"SAT\",\"SUN\",\"MON\"]},\"SpecificTime\":{\"ToTime\":\"2230\",\"FromTime\":\"1930\"}}],\"HostMappings\":[{\"Server\":\"LocalControlM\",\"Host\":\"host1\",\"MapTo\":\"host2\"},{\"Server\":\"LocalControlM\",\"Host\":\"host3\",\"MapTo\":\"host4\"}]}}",
        "description": "Advanced Workload Policy"
    } ,
    "Workload Policy Basic": {
        "prefix": "jac.run.workload.policy.basic",
        "body": "{\"Workload_Policy\": {\"Type\": \"WorkloadPolicy\",\"Description\": \"My Workload Policy\"}",
        "description": "Advanced Workload Policy"
    } ,
    "Workload Policy Filter": {
        "prefix": "jac.run.workload.policy.filter",
        "body": "\"Filter\": {\"Folder\": \"Folder5\",\"Server\": \"LocalControlM\",\"Application\": \"app3\",\"SubApplication\": \"subapp7\",\"JobName\": \"MyJob\",\"Host\": \"host1\"}",
        "description": "Advanced Workload Filter"
    } ,
    "Workload Policy Running Jobs": {
        "prefix": "jac.run.workload.policy.running.jobs",
        "body": "\"RunningJobs\":[{\"Server\":\"LocalControlM\",\"Quantity\":\"5\",\"RangeDates\":{\"ToDate\":\"20210711\",\"FromDate\":\"20210711\"},\"SpecificTime\":{\"ToTime\":\"1130\",\"FromTime\":\"1030\"}},{\"Server\":\"Global\",\"Quantity\":\"3\",\"PeriodicDays\":{\"DaysOfWeek\":[\"WED\",\"FRI\"]},\"SpecificTime\":{\"ToTime\":\"1100\",\"FromTime\":\"1000\"}}]",
        "description": "Advanced Workload Running Jobs"
    } ,
    "Workload Policy Resource Pool": {
        "prefix": "jac.run.workload.policy.resource.pool",
        "body": "\"ResourcePools\":[{\"Server\":\"LocalControlM\",\"Resource\":\"pool1\",\"Quantity\":\"2\",\"PeriodicDays\":{\"DaysOfWeek\":[\"SAT\",\"SUN\",\"MON\"]},\"SpecificTime\":{\"ToTime\":\"2230\",\"FromTime\":\"1930\"}}]",
        "description": "Advanced Workload Resource Pool"
    },
    "Workload Policy Host Mapping": {
        "prefix": "jac.run.workload.policy.host.mapping",
        "body": "\"HostMappings\":[{\"Server\":\"LocalControlM\",\"Host\":\"host1\",\"MapTo\":\"host2\"},{\"Server\":\"LocalControlM\",\"Host\":\"host3\",\"MapTo\":\"host4\"}]",
        "description": "Advanced Workload Host Mapping"
    },
    "Update Job Alerts": {
        "prefix": "jac.run.alerts.update",
        "body": "{\"alertIds\" : [30,31],\"urgency\":\"Normal\",\"comment\":\"update\"}",
        "description": "Update Job Alerts"
    },
    "Update Job Alert Status": {
        "prefix": "jac.run.alerts.status",
        "body": "{\"alertIds\" : [20],\"status\":\"Reviewed\"}",
        "description": "Update Job Alert Status"
    },
    "Fix Failed Job NOTOK": {
        "prefix": "jac.job.fix.failed.job",
        "body": "\"DoCorrectiveFlowNeeded\":{\"Type\":\"If\",\"CompletionStatus\":\"NOTOK\",\"Correction\":{\"Type\":\"Run\",\"Folder\":\"CorrectiveFlow\"}}",
        "description": "Fix Failed Job NOTOK"
    }   
}